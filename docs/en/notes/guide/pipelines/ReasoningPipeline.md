---

title: Reasoning Data Synthesis Pipeline
icon: mdi:brain
createTime: 2025/06/16 13:08:42
permalink: /en/guide/reasoningpipeline/

---

# Reasoning Data Synthesis Pipeline

## 1. Overview

The core goal of the **Reasoning Data Synthesis Pipeline** is to expand the scale and diversity of existing datasets through the synthesis and processing of mathematical question-and-answer data, thereby providing richer training data for model fine-tuning. The pipeline includes multiple processing steps (such as question filtering, question synthesis, answer generation and validation, etc.) that transform raw mathematical question data into high-quality question-and-answer data. Furthermore, the generated data undergoes classification, difficulty scoring, and deduplication, ultimately forming a high-quality dataset suitable for various reasoning tasks.

We support the following use cases:

* High-quality synthesis of strong reasoning instruction fine-tuning data
* Large-scale mathematical pre-training data generation

The main workflow of the pipeline is as follows:

1. **Question Processing**: Filters non-mathematical questions, synthesizes new questions, verifies the correctness of the questions, scores the difficulty, and classifies the categories.
2. **Answer Generation and Processing**: Processes answers based on the standard answers or the answers generated by the model, including format filtering, length filtering, and correctness validation.
3. **Data Deduplication**: Deduplicates the generated question-and-answer data to ensure the quality of the dataset.

## 2. Data Flow and Pipeline Logic

### 1. **Input Data**

The input data for the pipeline primarily includes the following fields:

* **instruction**: The question text, typically a mathematical problem or task description.
* **golden\_answer**: The standard answer (if available), applicable to datasets that contain standard answers.
* **solution**: The known answer or reasoning process (if available).

These input data can be stored in designated files (such as `json` or `jsonl`) and managed and read via the `FileStorage` object. In the provided example, the default data path is loaded. In practical use, you can modify the path to load custom data and cache paths:

```python
self.storage = FileStorage(
    first_entry_file_name="../dataflow/example/ReasoningPipeline/pipeline_math_short.json",
    cache_path="./cache_local",
    file_name_prefix="dataflow_cache_step",
    cache_type="jsonl",
)
```

### 2. **Question Handling**

#### 2.1 **Question Filtering (QuestionFilter)**

The first step of the pipeline is to filter out invalid mathematical questions through the **Question Filter** operator (`QuestionFilter`). This step is critical as it ensures that only valid mathematical problems are passed to subsequent steps, preventing unrelated or incorrect questions from affecting data synthesis.

**Function:**

* Removes non-mathematical problems (e.g., natural language problems, non-mathematical questions).
* Ensures that only valid mathematical questions are processed.

**Input**: Original mathematical questions
**Output**: Cleaned and valid mathematical questions

#### 2.2 **Question Synthesis (QuestionGenerator)**

After filtering, the **Question Synthesis** operator (`QuestionGenerator`) generates new mathematical questions based on existing ones to enhance the dataset's diversity and scale.

**Function:**

* Generates new variations or similar questions based on existing ones.
* Enhances the dataset to improve the model's generalization capabilities.

**Input**: Valid questions after filtering
**Output**: Generated new questions

#### 2.3 **Question Filtering (QuestionFilter)**

The newly generated questions are then filtered again through the **Question Filter** operator to ensure their validity. This step confirms that the generated questions meet the required mathematical reasoning standards, filtering out any invalid ones.

**Function:**

* Re-validates the questions for their validity.
* Filters out any incorrect synthesized questions.

**Input**: Generated new questions
**Output**: Valid synthesized questions

#### 2.4 **Question Difficulty Classification (QuestionDifficultyClassifier)**

The **Question Difficulty Classification** operator (`QuestionDifficultyClassifier`) assigns difficulty scores to the synthesized questions. This step categorizes the questions into difficulty levels (e.g., 0-10), which helps in subsequent data analysis and model fine-tuning.

**Function:**

* Assigns a difficulty score to each question (e.g., 0-10).
* Provides a difficulty label for the questions, aiding in further analysis.

**Input**: Valid synthesized questions
**Output**: Difficulty scores for each question

#### 2.5 **Question Category Classification (QuestionCategoryClassifier)**

The **Question Category Classification** operator (`QuestionCategoryClassifier`) classifies questions into different mathematical categories (e.g., algebra, geometry, probability, etc.). This step helps analyze the distribution and diversity of the questions.

**Function:**

* Categorizes questions into different mathematical topics (e.g., geometry, combinatorics, etc.).
* Facilitates further analysis and grouping for specific tasks.

**Input**: Valid synthesized questions
**Output**: Category labels for the questions

### 3. **Answer Handling**

#### 3.1 **Answer Branching (AnswerPipelineRoot)**

After processing the questions, the pipeline enters the answer generation phase. If the dataset contains a standard answer (`golden_answer`), the data flow will enter one branch; otherwise, it will follow the pseudo-answer generation path.

**Function:**

* Decides whether to use the standard answer or generate a pseudo-answer.
* If a standard answer exists, the reasoning process related to the answer is generated; otherwise, a pseudo-answer is generated via the model.

**Input**: Output of the question (and standard answer if available)
**Output**: Standard answer branch or pseudo-answer branch

#### 3.2 **Answer Generation (AnswerGenerator)**

For cases with a standard answer, the **Answer Generation** operator (`AnswerGenerator`) generates an answer with the reasoning process, providing a chain of thought to enhance the answer's reliability and transparency. For cases without a standard answer, this step becomes **Pseudo Answer Generation** (via `PseudoAnswerGenerator`), where the model generates multiple answers for the same question and selects the most frequent one as the pseudo-answer.

**Function:**

* Generates a detailed reasoning process based on the question and standard answer.
* Ensures transparency and interpretability of the answer.

**Input**: Question text (and standard answer)
**Output**: For standard answers: generated reasoning process (chain of thought); for no standard answer: pseudo-answer and reasoning process.

#### 3.3 **Answer Format Filtering (AnswerFormatterFilter)**

The generated answer passes through the **Answer Format Filtering** operator (`AnswerFormatterFilter`), ensuring that it adheres to predefined format requirements. This step ensures the generated answer is well-structured and valid, preventing issues in subsequent steps.

**Function:**

* Ensures that the answer format is correct.

**Input**: Generated answer (chain of thought)
**Output**: Formatted answer that meets the requirements

#### 3.4 **Answer Length Filtering (AnswerTokenLengthFilter)**

Next, the **Answer Length Filtering** operator (`AnswerTokenLengthFilter`) filters answers based on predefined maximum lengths, eliminating answers that are too long or too short, ensuring that the generated answer has an appropriate length.

**Function:**

* Filters out answers that are too long or too short.
* Ensures that the answer length is within a reasonable range.

**Input**: Generated answer
**Output**: Answer with valid length

#### 3.5 **Answer Validation and Deduplication (AnswerGroundTruthFilter, AnswerNgramFilter)**

Finally, the generated answer undergoes two steps: **Answer Validation** (`AnswerGroundTruthFilter`) and **Answer Deduplication** (`AnswerNgramFilter`):

* **Answer Validation**: Compares the generated answer with the standard answer (if available) to verify its correctness.
* **Answer Deduplication**: Uses the N-gram algorithm to remove duplicate answers, ensuring that each question has a unique answer.

**Function:**

* Validates the correctness of the answer.
* Deduplicates answers to ensure uniqueness.

**Input**: Generated answer
**Output**: Validated and deduplicated answer

### 4. **Output Data**

After the steps mentioned above, the pipeline generates the following output data:

* **instruction**: The question text
* **generated\_cot**: The model-generated chain of thought
* **output**: The final model-generated answer
* **golden\_answer**: The standard answer (if available)
* **Synth\_or\_Input**: Marks whether the data is from the input (`input`) or synthesized by the pipeline (`synth`)
* **Difficulty**: The difficulty score of the question (0-10)
* **primary\_category**: The primary category of the question
* **secondary\_category**: The secondary category of the question

## 3. Running the Pipeline

The pipeline can be executed with simple Python commands to suit different data requirements:

* **For strong reasoning instruction fine-tuning data synthesis**:

  ```bash
  python test/test_reasoning.py
  ```

* **For large-scale pre-training data synthesis**:

  ```bash
  python test/test_reasoning_pretrain.py
  ```